{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temat 1. Własna sieć neuronowa\n",
    "Przykładowe zadanie: klasyfikacja kwiatów irysa (Fisher's iris dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"./project\")\n",
    "Pkg.add(\"MLDatasets\")\n",
    "Pkg.add(\"IJulia\")\n",
    "Pkg.add(\"StableRNGs\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"PyPlot\")\n",
    "Pkg.add(\"MLDataUtils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RDatasets\n",
    "using Random\n",
    "using Plots\n",
    "using DataFrames\n",
    "using MLDataUtils\n",
    "using Random\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = Matrix(dataset(\"datasets\", \"iris\"))\n",
    "using Random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris[:,1:4]\n",
    "y = iris[:,5]\n",
    "println(\"X data shape: \", size(X))\n",
    "println(\"Y data shape: \", size(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = [\"setosa\", \"virginica\", \"versicolor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function reshape_data(data_x, data_y,species_vec)\n",
    "    x_reshaped = []\n",
    "    y_reshaped = []\n",
    "    \n",
    "    for i = 1:size(data_x)[1]\n",
    "        push!(x_reshaped, data_x[i,:])\n",
    "        y = zeros(3)\n",
    "        if data_y[i] == species_vec[1]\n",
    "            y[1] = 1.0\n",
    "        elseif data_y[i] == species_vec[2]\n",
    "            y[2] = 1.0\n",
    "        elseif data_y[i] == species_vec[3]\n",
    "            y[3] = 1.0\n",
    "        end\n",
    "        push!(y_reshaped,y)\n",
    "    end\n",
    "    \n",
    "    d = [data for data in zip(x_reshaped, y_reshaped)]\n",
    "    \n",
    "    return d\n",
    "end\n",
    "\n",
    "data = reshape_data(X, y,species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podział na dane treningowe i testowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(1234)\n",
    "train, test = splitobs(shuffleobs(data), at = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Różniczkowanie w przód"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = function jacobian(f, args::Vector{T}) where {T <:Number}\n",
    "    jacobian_columns = Matrix{T}[]\n",
    "    \n",
    "    for i=1:length(args)\n",
    "        x = Dual{T}[]\n",
    "        for j=1:length(args)\n",
    "            seed = (i == j)\n",
    "            push!(x, seed ?\n",
    "                Dual(args[j], one(args[j])) :\n",
    "                Dual(args[j],zero(args[j])) )\n",
    "        end\n",
    "        column = partials.([f(x)...])\n",
    "        push!(jacobian_columns, column[:,:])\n",
    "    end\n",
    "    hcat(jacobian_columns...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Layer\n",
    "    m::Int\n",
    "    n::Int\n",
    "    activation::Function\n",
    "    W::Matrix\n",
    "    dW::Matrix\n",
    "    b::Vector\n",
    "    db::Vector\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function NeuralNetwork()\n",
    "    layer = []\n",
    "    function AddLayer(m,n,activation) layer_::Layer = Layer(m,n,activation,randn(n,m),randn(n,m),randn(n),randn(n)); push!(layer, layer_);end\n",
    "    () -> (AddLayer,layer)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward(net, x, y) =\n",
    "let\n",
    "    for i=1:(size(net.layer)[1])\n",
    "        x = net.layer[i].activation.(reshape(net.layer[i].W, net.layer[i].n, net.layer[i].m) * x .+ net.layer[i].b)\n",
    "        end \n",
    "        E = mean_squared_loss(y, x)\n",
    "        return E\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_w(net, x, y, w, j) =\n",
    "    let \n",
    "        tmp = randn(net.layer[j].n, net.layer[j].m)\n",
    "        tmp[:,:] = net.layer[j].W\n",
    "        net.layer[j].W = w[:, :]\n",
    "    \n",
    "        for i=1:(size(net.layer)[1])\n",
    "            x = net.layer[i].activation.(reshape(net.layer[i].W, net.layer[i].n, net.layer[i].m) * x .+ net.layer[i].b)\n",
    "        end\n",
    "         \n",
    "        net.layer[j].W = tmp[:,:]\n",
    "        E = mean_squared_loss(y, x)\n",
    "        return E\n",
    "    end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_b(net, x, y, b, j) =\n",
    "    let \n",
    "        tmp = randn(net.layer[j].n)\n",
    "        tmp[:] = net.layer[j].b\n",
    "        net.layer[j].b = b[:]\n",
    "    \n",
    "        for i=1:(size(net.layer)[1])\n",
    "            x = net.layer[i].activation.(reshape(net.layer[i].W, net.layer[i].n, net.layer[i].m) * x .+ net.layer[i].b)\n",
    "        end\n",
    "         \n",
    "        net.layer[j].b = tmp[:]\n",
    "        E = mean_squared_loss(y, x)\n",
    "        return E\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backpropagation(net, x, y) =\n",
    "    let\n",
    "        for i=1:(size(net.layer)[1])\n",
    "            net.layer[i].dW[:] = J(w-> forward_w(net,x, y, w, i), net.layer[i].dW[:])\n",
    "            net.layer[i].db[:] = J(b-> forward_b(net,x, y, b, i), net.layer[i].db[:])\n",
    "        end\n",
    "    end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update(net, x, y, α::Float64) =\n",
    "    let\n",
    "        for i=1:(size(net.layer)[1])\n",
    "            net.layer[i].W -= α * net.layer[i].dW;\n",
    "            net.layer[i].b -= α * net.layer[i].db;\n",
    "        end\n",
    "    end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training(net, data_set, α::Float64) =\n",
    "    let\n",
    "        Loss_history = Float64[]\n",
    "        for j = 1:5\n",
    "            epoch_L = []\n",
    "            for i = 1:(length(data_set))\n",
    "                x = data_set[i][1]\n",
    "                y = data_set[i][2]\n",
    "                Ei = forward(net, x, y)\n",
    "                push!(epoch_L, Ei)\n",
    "                backpropagation(net, x, y)\n",
    "                update(net, x, y, α)\n",
    "            end\n",
    "            push!(Loss_history, std(epoch_L))\n",
    "        end\n",
    "\n",
    "        return Loss_history\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(net,x) = \n",
    "    let   \n",
    "        for i=1:(size(net.layer)[1])\n",
    "            x = net.layer[i].activation.(reshape(net.layer[i].W, net.layer[i].n, net.layer[i].m) * x .+ net.layer[i].b)\n",
    "        end\n",
    "\n",
    "        return argmax(x)\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(network, data_set) =\n",
    "    let\n",
    "        return string(\"Accuracy: \", sum([predict(network,x[1]) == argmax(x[2]) ? 1 : 0 for x in data_set])/length(data_set)*100, \"%\")\n",
    "    end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utworzenie sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU(x) = max(zero(x), x)\n",
    "# σ(x) = one(x) / (one(x) + exp(-x))\n",
    "# tanh(x) = 2.0 / (one(x) + exp(-2.0x)) - one(x)\n",
    "# softmax(x)  =  exp.(x) ./ sum(exp.(x));\n",
    "Random.seed!(2)\n",
    "net = NeuralNetwork()\n",
    "net.AddLayer(4, 4, ReLU)\n",
    "net.AddLayer(4, 3, σ)\n",
    "history = training(net, train, 0.01)\n",
    "@show Plots.plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(net,test[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(net,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
