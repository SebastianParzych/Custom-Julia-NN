{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temat 1. Własna sieć neuronowa\n",
    "Przykładowe zadanie: klasyfikacja kwiatów irysa (Fisher's iris dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `e:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MappedArrays ─────── v0.4.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m InverseFunctions ─── v0.1.7\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StatsAPI ─────────── v1.4.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LearnBase ────────── v0.3.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LogExpFunctions ──── v0.3.15\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLDataUtils ──────── v0.5.4\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLDataPattern ────── v0.5.4\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ChainRulesCore ───── v1.15.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLLabelUtils ─────── v0.5.7\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ChangesOfVariables ─ v0.1.3\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StatsBase ────────── v0.33.17\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Project.toml`\n",
      " \u001b[90m [cc2ba9b6] \u001b[39m\u001b[92m+ MLDataUtils v0.5.4\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Manifest.toml`\n",
      " \u001b[90m [d360d2e6] \u001b[39m\u001b[92m+ ChainRulesCore v1.15.0\u001b[39m\n",
      " \u001b[90m [9e997f8a] \u001b[39m\u001b[92m+ ChangesOfVariables v0.1.3\u001b[39m\n",
      " \u001b[90m [ffbed154] \u001b[39m\u001b[92m+ DocStringExtensions v0.8.6\u001b[39m\n",
      " \u001b[90m [3587e190] \u001b[39m\u001b[92m+ InverseFunctions v0.1.7\u001b[39m\n",
      " \u001b[90m [92d709cd] \u001b[39m\u001b[92m+ IrrationalConstants v0.1.1\u001b[39m\n",
      " \u001b[90m [7f8f8fb0] \u001b[39m\u001b[92m+ LearnBase v0.3.0\u001b[39m\n",
      " \u001b[90m [2ab3a3ac] \u001b[39m\u001b[92m+ LogExpFunctions v0.3.15\u001b[39m\n",
      " \u001b[90m [9920b226] \u001b[39m\u001b[92m+ MLDataPattern v0.5.4\u001b[39m\n",
      " \u001b[90m [cc2ba9b6] \u001b[39m\u001b[92m+ MLDataUtils v0.5.4\u001b[39m\n",
      " \u001b[90m [66a33bbf] \u001b[39m\u001b[92m+ MLLabelUtils v0.5.7\u001b[39m\n",
      " \u001b[90m [dbb5928d] \u001b[39m\u001b[92m+ MappedArrays v0.4.1\u001b[39m\n",
      " \u001b[90m [82ae8749] \u001b[39m\u001b[92m+ StatsAPI v1.4.0\u001b[39m\n",
      " \u001b[90m [2913bbd2] \u001b[39m\u001b[92m+ StatsBase v0.33.17\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[33m  ✓ \u001b[39m\u001b[90mStatsAPI\u001b[39m\n",
      "\u001b[33m  ✓ \u001b[39m\u001b[90mInverseFunctions\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMappedArrays\u001b[39m\n",
      "\u001b[33m  ✓ \u001b[39m\u001b[90mChainRulesCore\u001b[39m\n",
      "\u001b[33m  ✓ \u001b[39m\u001b[90mChangesOfVariables\u001b[39m\n",
      "\u001b[33m  ✓ \u001b[39m\u001b[90mLogExpFunctions\u001b[39m\n",
      "\u001b[33m  ✓ \u001b[39m\u001b[90mStatsBase\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLearnBase\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMLLabelUtils\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMLDataPattern\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mMLDataUtils\n",
      "  11 dependencies successfully precompiled in 19 seconds (69 already precompiled, 2 skipped during auto due to previous errors)\n",
      "  \u001b[33m6\u001b[39m dependencies precompiled but different versions are currently loaded. Restart julia to access the new versions\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"./project\")\n",
    "Pkg.add(\"MLDatasets\")\n",
    "Pkg.add(\"IJulia\")\n",
    "Pkg.add(\"StableRNGs\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"PyPlot\")\n",
    "Pkg.add(\"MLDataUtils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RDatasets\n",
    "using Random\n",
    "using Plots\n",
    "using DataFrames\n",
    "using MLDataUtils\n",
    "using Random\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150×5 Matrix{Any}:\n",
       " 5.1  3.5  1.4  0.2  \"setosa\"\n",
       " 4.9  3.0  1.4  0.2  \"setosa\"\n",
       " 4.7  3.2  1.3  0.2  \"setosa\"\n",
       " 4.6  3.1  1.5  0.2  \"setosa\"\n",
       " 5.0  3.6  1.4  0.2  \"setosa\"\n",
       " 5.4  3.9  1.7  0.4  \"setosa\"\n",
       " 4.6  3.4  1.4  0.3  \"setosa\"\n",
       " 5.0  3.4  1.5  0.2  \"setosa\"\n",
       " 4.4  2.9  1.4  0.2  \"setosa\"\n",
       " 4.9  3.1  1.5  0.1  \"setosa\"\n",
       " 5.4  3.7  1.5  0.2  \"setosa\"\n",
       " 4.8  3.4  1.6  0.2  \"setosa\"\n",
       " 4.8  3.0  1.4  0.1  \"setosa\"\n",
       " ⋮                   \n",
       " 6.0  3.0  4.8  1.8  \"virginica\"\n",
       " 6.9  3.1  5.4  2.1  \"virginica\"\n",
       " 6.7  3.1  5.6  2.4  \"virginica\"\n",
       " 6.9  3.1  5.1  2.3  \"virginica\"\n",
       " 5.8  2.7  5.1  1.9  \"virginica\"\n",
       " 6.8  3.2  5.9  2.3  \"virginica\"\n",
       " 6.7  3.3  5.7  2.5  \"virginica\"\n",
       " 6.7  3.0  5.2  2.3  \"virginica\"\n",
       " 6.3  2.5  5.0  1.9  \"virginica\"\n",
       " 6.5  3.0  5.2  2.0  \"virginica\"\n",
       " 6.2  3.4  5.4  2.3  \"virginica\"\n",
       " 5.9  3.0  5.1  1.8  \"virginica\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = Matrix(dataset(\"datasets\", \"iris\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X data shape: (150, 4)\n",
      "Y data shape: (150,)\n"
     ]
    }
   ],
   "source": [
    "X = iris[:,1:4]\n",
    "y = iris[:,5]\n",
    "println(\"X data shape: \", size(X))\n",
    "println(\"Y data shape: \", size(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{String}:\n",
       " \"setosa\"\n",
       " \"virginica\"\n",
       " \"versicolor\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species = [\"setosa\", \"virginica\", \"versicolor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150-element Vector{Tuple{Vector{Any}, Vector{Float64}}}:\n",
       " ([5.1, 3.5, 1.4, 0.2], [1.0, 0.0, 0.0])\n",
       " ([4.9, 3.0, 1.4, 0.2], [1.0, 0.0, 0.0])\n",
       " ([4.7, 3.2, 1.3, 0.2], [1.0, 0.0, 0.0])\n",
       " ([4.6, 3.1, 1.5, 0.2], [1.0, 0.0, 0.0])\n",
       " ([5.0, 3.6, 1.4, 0.2], [1.0, 0.0, 0.0])\n",
       " ([5.4, 3.9, 1.7, 0.4], [1.0, 0.0, 0.0])\n",
       " ([4.6, 3.4, 1.4, 0.3], [1.0, 0.0, 0.0])\n",
       " ([5.0, 3.4, 1.5, 0.2], [1.0, 0.0, 0.0])\n",
       " ([4.4, 2.9, 1.4, 0.2], [1.0, 0.0, 0.0])\n",
       " ([4.9, 3.1, 1.5, 0.1], [1.0, 0.0, 0.0])\n",
       " ([5.4, 3.7, 1.5, 0.2], [1.0, 0.0, 0.0])\n",
       " ([4.8, 3.4, 1.6, 0.2], [1.0, 0.0, 0.0])\n",
       " ([4.8, 3.0, 1.4, 0.1], [1.0, 0.0, 0.0])\n",
       " ⋮\n",
       " ([6.0, 3.0, 4.8, 1.8], [0.0, 1.0, 0.0])\n",
       " ([6.9, 3.1, 5.4, 2.1], [0.0, 1.0, 0.0])\n",
       " ([6.7, 3.1, 5.6, 2.4], [0.0, 1.0, 0.0])\n",
       " ([6.9, 3.1, 5.1, 2.3], [0.0, 1.0, 0.0])\n",
       " ([5.8, 2.7, 5.1, 1.9], [0.0, 1.0, 0.0])\n",
       " ([6.8, 3.2, 5.9, 2.3], [0.0, 1.0, 0.0])\n",
       " ([6.7, 3.3, 5.7, 2.5], [0.0, 1.0, 0.0])\n",
       " ([6.7, 3.0, 5.2, 2.3], [0.0, 1.0, 0.0])\n",
       " ([6.3, 2.5, 5.0, 1.9], [0.0, 1.0, 0.0])\n",
       " ([6.5, 3.0, 5.2, 2.0], [0.0, 1.0, 0.0])\n",
       " ([6.2, 3.4, 5.4, 2.3], [0.0, 1.0, 0.0])\n",
       " ([5.9, 3.0, 5.1, 1.8], [0.0, 1.0, 0.0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function reshape_data(data_x, data_y,species_vec)\n",
    "    x_reshaped = []\n",
    "    y_reshaped = []\n",
    "    \n",
    "    for i = 1:size(data_x)[1]\n",
    "        push!(x_reshaped, data_x[i,:])\n",
    "        y = zeros(3)\n",
    "        if data_y[i] == species_vec[1]\n",
    "            y[1] = 1.0\n",
    "        elseif data_y[i] == species_vec[2]\n",
    "            y[2] = 1.0\n",
    "        elseif data_y[i] == species_vec[3]\n",
    "            y[3] = 1.0\n",
    "        end\n",
    "        push!(y_reshaped,y)\n",
    "    end\n",
    "    \n",
    "    d = [data for data in zip(x_reshaped, y_reshaped)]\n",
    "    \n",
    "    return d\n",
    "end\n",
    "\n",
    "data = reshape_data(X, y,species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podział na dane treningowe i testowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tuple{Vector{Any}, Vector{Float64}}[([4.8, 3.0, 1.4, 0.1], [1.0, 0.0, 0.0]), ([7.2, 3.2, 6.0, 1.8], [0.0, 1.0, 0.0]), ([6.3, 2.8, 5.1, 1.5], [0.0, 1.0, 0.0]), ([4.3, 3.0, 1.1, 0.1], [1.0, 0.0, 0.0]), ([5.8, 2.7, 5.1, 1.9], [0.0, 1.0, 0.0]), ([5.0, 3.2, 1.2, 0.2], [1.0, 0.0, 0.0]), ([6.9, 3.1, 5.1, 2.3], [0.0, 1.0, 0.0]), ([4.6, 3.4, 1.4, 0.3], [1.0, 0.0, 0.0]), ([6.9, 3.1, 4.9, 1.5], [0.0, 0.0, 1.0]), ([6.4, 3.2, 4.5, 1.5], [0.0, 0.0, 1.0])  …  ([6.7, 3.1, 5.6, 2.4], [0.0, 1.0, 0.0]), ([6.1, 2.6, 5.6, 1.4], [0.0, 1.0, 0.0]), ([4.7, 3.2, 1.3, 0.2], [1.0, 0.0, 0.0]), ([6.5, 3.0, 5.2, 2.0], [0.0, 1.0, 0.0]), ([5.5, 2.5, 4.0, 1.3], [0.0, 0.0, 1.0]), ([6.5, 3.0, 5.8, 2.2], [0.0, 1.0, 0.0]), ([5.4, 3.0, 4.5, 1.5], [0.0, 0.0, 1.0]), ([4.7, 3.2, 1.6, 0.2], [1.0, 0.0, 0.0]), ([5.7, 4.4, 1.5, 0.4], [1.0, 0.0, 0.0]), ([4.9, 3.1, 1.5, 0.2], [1.0, 0.0, 0.0])], Tuple{Vector{Any}, Vector{Float64}}[([6.9, 3.2, 5.7, 2.3], [0.0, 1.0, 0.0]), ([5.8, 4.0, 1.2, 0.2], [1.0, 0.0, 0.0]), ([5.7, 2.6, 3.5, 1.0], [0.0, 0.0, 1.0]), ([6.9, 3.1, 5.4, 2.1], [0.0, 1.0, 0.0]), ([5.5, 2.4, 3.8, 1.1], [0.0, 0.0, 1.0]), ([5.7, 3.0, 4.2, 1.2], [0.0, 0.0, 1.0]), ([7.7, 2.6, 6.9, 2.3], [0.0, 1.0, 0.0]), ([5.2, 3.4, 1.4, 0.2], [1.0, 0.0, 0.0]), ([5.0, 3.5, 1.3, 0.3], [1.0, 0.0, 0.0]), ([6.0, 2.2, 4.0, 1.0], [0.0, 0.0, 1.0])  …  ([7.2, 3.6, 6.1, 2.5], [0.0, 1.0, 0.0]), ([6.2, 2.2, 4.5, 1.5], [0.0, 0.0, 1.0]), ([7.1, 3.0, 5.9, 2.1], [0.0, 1.0, 0.0]), ([6.5, 3.0, 5.5, 1.8], [0.0, 1.0, 0.0]), ([6.3, 2.7, 4.9, 1.8], [0.0, 1.0, 0.0]), ([6.7, 3.0, 5.0, 1.7], [0.0, 0.0, 1.0]), ([6.3, 2.3, 4.4, 1.3], [0.0, 0.0, 1.0]), ([6.0, 3.0, 4.8, 1.8], [0.0, 1.0, 0.0]), ([5.8, 2.6, 4.0, 1.2], [0.0, 0.0, 1.0]), ([5.7, 2.8, 4.5, 1.3], [0.0, 0.0, 1.0])])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = splitobs(shuffleobs(data), at = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Różniczkowanie w przód"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zdefiniowanie struktury\n",
    "struct Dual{T <:Number} <:Number\n",
    "     v::T\n",
    "    dv::T\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przeciążenie podstawowych operatorów\n",
    "import Base: +, -, *, /\n",
    "-(x::Dual)          = Dual(-x.v,       -x.dv)\n",
    "+(x::Dual, y::Dual) = Dual( x.v + y.v,  x.dv + y.dv)\n",
    "-(x::Dual, y::Dual) = Dual( x.v - y.v,  x.dv - y.dv)\n",
    "*(x::Dual, y::Dual) = Dual( x.v * y.v,  x.dv * y.v + x.v * y.dv)\n",
    "/(x::Dual, y::Dual) = Dual( x.v / y.v, (x.dv * y.v - x.v * y.dv)/y.v^2)\n",
    "# Przeciążenie podstawowych funkcji\n",
    "import Base: abs, sin, cos, tan, exp, sqrt, isless\n",
    "abs(x::Dual)  = Dual(abs(x.v),sign(x.v)*x.dv)\n",
    "sin(x::Dual)  = Dual(sin(x.v), cos(x.v)*x.dv)\n",
    "cos(x::Dual)  = Dual(cos(x.v),-sin(x.v)*x.dv)\n",
    "tan(x::Dual)  = Dual(tan(x.v), one(x.v)*x.dv + tan(x.v)^2*x.dv)\n",
    "exp(x::Dual)  = Dual(exp(x.v), exp(x.v)*x.dv)\n",
    "sqrt(x::Dual) = Dual(sqrt(x.v),.5/sqrt(x.v) * x.dv)\n",
    "isless(x::Dual, y::Dual) = x.v < y.v;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promocja typów i konwersja\n",
    "import Base: convert, promote_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dual{Float64}[Dual(1, 2), Dual(3, 0)] = Dual{Float64}[Dual{Float64}(1.0, 2.0), Dual{Float64}(3.0, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "convert(::Type{Dual{T}}, x::Dual) where T = Dual(convert(T, x.v), convert(T, x.dv))\n",
    "@show Dual{Float64}[Dual(1,2), Dual(3,0)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dual{Float64}[1, 2, 3] = Dual{Float64}[Dual{Float64}(1.0, 0.0), Dual{Float64}(2.0, 0.0), Dual{Float64}(3.0, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "convert(::Type{Dual{T}}, x::Number) where T = Dual(convert(T, x), zero(T))\n",
    "@show Dual{Float64}[1, 2, 3];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dual(1, 2) * 3 = Dual{Int64}(3, 6)\n"
     ]
    }
   ],
   "source": [
    "promote_rule(::Type{Dual{T}}, ::Type{R}) where {T,R} = Dual{promote_type(T,R)}\n",
    "@show Dual(1,2) * 3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Base: show\n",
    "show(io::IO, x::Dual) = print(io, \"(\", x.v, \") + [\", x.dv, \"ϵ]\");\n",
    "value(x::Dual) = x.v;\n",
    "partials(x::Dual) = x.dv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "derivative (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = derivative(f, x) = partials(f(Dual(x, one(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jacobian (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J = function jacobian(f, args::Vector{T}) where {T <:Number}\n",
    "    jacobian_columns = Matrix{T}[]\n",
    "    \n",
    "    for i=1:length(args)\n",
    "        x = Dual{T}[]\n",
    "        for j=1:length(args)\n",
    "            seed = (i == j)\n",
    "            push!(x, seed ?\n",
    "                Dual(args[j], one(args[j])) :\n",
    "                Dual(args[j],zero(args[j])) )\n",
    "        end\n",
    "        column = partials.([f(x)...])\n",
    "        push!(jacobian_columns, column[:,:])\n",
    "    end\n",
    "    hcat(jacobian_columns...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hessian (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = function hessian(f, args::Vector)\n",
    "    ∇f(x::Vector) = J(f, x)\n",
    "    J(∇f, args)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagonal (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import LinearAlgebra: diagm\n",
    "diagonal(m) = diagm(0 => vec(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcje aktywacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReLU(x) = max(zero(x), x)\n",
    "σ(x) = one(x) / (one(x) + exp(-x))\n",
    "tanh(x) = 2.0 / (one(x) + exp(-2.0x)) - one(x)\n",
    "softmax(x)  =  exp.(x) ./ sum(exp.(x));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcja kosztu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_squared_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_loss(y::Vector, ŷ::Vector) = sum(0.5(y - ŷ).^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sieć"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Layer\n",
    "    m::Int\n",
    "    n::Int\n",
    "    activation::Function\n",
    "    W::Matrix\n",
    "    dW::Matrix\n",
    "    b::Vector\n",
    "    db::Vector\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function NeuralNetwork()\n",
    "    layer = []\n",
    "    function AddLayer(m,n,activation) layer_::Layer = Layer(m,n,activation,randn(n,m),randn(n,m),randn(n),randn(n)); push!(layer, layer_);end\n",
    "    () -> (AddLayer,layer)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forward (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(net, x, y) =\n",
    "    let\n",
    "        for i=1:(size(net.layer)[1])\n",
    "            x = net.layer[i].activation.(reshape(net.layer[i].W, net.layer[i].n, net.layer[i].m) * x .+ net.layer[i].b)\n",
    "        end \n",
    "        E = mean_squared_loss(y, x)\n",
    "        return E\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forward_w (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_w(net, x, y, w, j) =\n",
    "    let \n",
    "        tmp = randn(net.layer[j].n, net.layer[j].m)\n",
    "        tmp[:,:] = net.layer[j].W\n",
    "        net.layer[j].W = w[:, :]\n",
    "    \n",
    "        for i=1:(size(net.layer)[1])\n",
    "            x = net.layer[i].activation.(reshape(net.layer[i].W, net.layer[i].n, net.layer[i].m) * x .+ net.layer[i].b)\n",
    "        end\n",
    "         \n",
    "        net.layer[j].W = tmp[:,:]\n",
    "        E = mean_squared_loss(y, x)\n",
    "        return E\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forward_b (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_b(net, x, y, b, j) =\n",
    "    let \n",
    "        tmp = randn(net.layer[j].n)\n",
    "        tmp[:] = net.layer[j].b\n",
    "        net.layer[j].b = b[:]\n",
    "    \n",
    "        for i=1:(size(net.layer)[1])\n",
    "            x = net.layer[i].activation.(reshape(net.layer[i].W, net.layer[i].n, net.layer[i].m) * x .+ net.layer[i].b)\n",
    "        end\n",
    "         \n",
    "        net.layer[j].b = tmp[:]\n",
    "        E = mean_squared_loss(y, x)\n",
    "        return E\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backpropagation (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backpropagation(net, x, y) =\n",
    "    let\n",
    "        for i=1:(size(net.layer)[1])\n",
    "            net.layer[i].dW[:] = J(w-> forward_w(net,x, y, w, i), net.layer[i].dW[:])\n",
    "            net.layer[i].db[:] = J(b-> forward_b(net,x, y, b, i), net.layer[i].db[:])\n",
    "        end\n",
    "    end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update (generic function with 1 method)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update(net, x, y, α::Float64) =\n",
    "    let\n",
    "        for i=1:(size(net.layer)[1])\n",
    "            net.layer[i].W -= α * net.layer[i].dW;\n",
    "            net.layer[i].b -= α * net.layer[i].db;\n",
    "        end\n",
    "    end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training (generic function with 1 method)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training(net, data_set, α::Float64) =\n",
    "    let\n",
    "        Loss_history = Float64[]\n",
    "        for j = 1:10\n",
    "            epoch_L = []\n",
    "            for i = 1:(length(data_set))\n",
    "                x = data_set[i][1]\n",
    "                y = data_set[i][2]\n",
    "                Ei = forward(net, x, y)\n",
    "                push!(epoch_L, Ei)\n",
    "                backpropagation(net, x, y)\n",
    "                update(net, x, y, α)\n",
    "            end\n",
    "            push!(Loss_history, std(epoch_L))\n",
    "        end\n",
    "\n",
    "        return Loss_history\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(net,x) = \n",
    "    let   \n",
    "        for i=1:(size(net.layer)[1])\n",
    "            x = net.layer[i].activation.(reshape(net.layer[i].W, net.layer[i].n, net.layer[i].m) * x .+ net.layer[i].b)\n",
    "        end\n",
    "\n",
    "        return argmax(x)\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(network, data_set) =\n",
    "    let\n",
    "        return string(\"Accuracy: \", sum([predict(network,x[1]) == argmax(x[2]) ? 1 : 0 for x in data_set])/length(data_set)*100, \"%\")\n",
    "    end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utworzenie sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Any}:\n",
       " Layer(4, 4, tanh, [-0.5936811989170308 -1.5577999726873633 -0.6161234406767674 0.4336196272869819; 0.9254145726612771 0.7798035177609629 -0.22157896951485945 -0.029190411330964932; -1.4414603738644214 -0.8931093598725464 0.06421188590067144 -0.6467752774468928; 0.1307024659005334 -0.9023527610206232 0.27393422060472855 1.2985296540185314], [-0.40554975532138426 1.2438411841768113 -0.03661066472445111 0.07169832610972623; -1.427682411740331 -1.2812530429090068 2.7669331215703035 -1.3139605495659208; 0.5896942766290914 -0.1391952993043809 0.4039410635983073 -0.7795902115109128; 0.9974475619051505 1.179597809524308 -1.7353425120414772 -1.2454111587223655], [1.1586280606506525, -0.48704220269661685, -0.31118900100972485, -0.7145607591125549], [-0.655348021334572, 0.971320854284574, -0.7243220928234003, 1.0085264959223117])\n",
       " Layer(4, 3, tanh, [-0.6966513207465287 1.238666736635454 1.0154063463720564 -1.26843246798782; 0.9614353363588359 -0.7718607815952832 -0.8018717628592237 -1.8175265868827382; 0.30097026116346753 -0.24916375158150056 0.6628934010976342 -0.6616881018945471], [1.5071716773902075 1.142118176113478 -0.6741403276451954 0.2091015827871879; 0.6586076331659971 0.8574368817304436 -1.2584786009512157 0.10446451773762362; -0.8104905690797994 0.03191921604971112 -0.5648477589513439 -0.9204546051868502], [-0.36873642639813764, 2.224852937830043, 0.8820263904713828], [-1.8743367177939319, -0.37858193266367773, -1.8432443791860063])\n",
       " Layer(3, 3, tanh, [0.9842585099010775 -0.33864683968056863 0.2230129571598655; 0.17382243791410673 0.7862866869241399 -0.2020778168079488; 2.3735763512966033 0.8340907208806506 0.17855553025577145], [0.7041126518130614 0.9638476189583373 -1.672516321656895; 0.5179278632084103 -0.484916346433424 -1.3063791656731587; 1.087858471867575 1.2280067374744517 -0.014188146434606022], [0.25389521999743603, -0.6344629571278559, -1.3181802375738707], [0.8244338224506267, -0.5169599632242226, 0.1634709454195786])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetwork()\n",
    "\n",
    "net.AddLayer(4, 4, tanh)\n",
    "net.AddLayer(4, 3, tanh)\n",
    "net.AddLayer(3, 3, tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       "   0.2801351392270275\n",
       "   0.08760145368988859\n",
       "   0.019674973815794257\n",
       "   0.0031232571198523723\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       " NaN"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = training(net,train,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots.plot(history) = Plot{Plots.GRBackend() n=1}\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n<defs>\n  <clipPath id=\"clip630\">\n    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip630)\" d=\"\nM0 1600 L2400 1600 L2400 0 L0 0  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip631\">\n    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip630)\" d=\"\nM186.274 1486.45 L2352.76 1486.45 L2352.76 47.2441 L186.274 47.2441  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip632\">\n    <rect x=\"186\" y=\"47\" width=\"2167\" height=\"1440\"/>\n  </clipPath>\n</defs>\n<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  474.684,1486.45 474.684,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  928.873,1486.45 928.873,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  1383.06,1486.45 1383.06,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  1837.25,1486.45 1837.25,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  2291.44,1486.45 2291.44,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  186.274,1486.45 2352.76,1486.45 \n  \"/>\n<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  474.684,1486.45 474.684,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  928.873,1486.45 928.873,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1383.06,1486.45 1383.06,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1837.25,1486.45 1837.25,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  2291.44,1486.45 2291.44,1467.55 \n  \"/>\n<path clip-path=\"url(#clip630)\" d=\"M469.337 1544.91 L485.656 1544.91 L485.656 1548.85 L463.712 1548.85 L463.712 1544.91 Q466.374 1542.16 470.957 1537.53 Q475.564 1532.88 476.744 1531.53 Q478.99 1529.01 479.869 1527.27 Q480.772 1525.51 480.772 1523.82 Q480.772 1521.07 478.828 1519.33 Q476.906 1517.6 473.804 1517.6 Q471.605 1517.6 469.152 1518.36 Q466.721 1519.13 463.943 1520.68 L463.943 1515.95 Q466.767 1514.82 469.221 1514.24 Q471.675 1513.66 473.712 1513.66 Q479.082 1513.66 482.277 1516.35 Q485.471 1519.03 485.471 1523.52 Q485.471 1525.65 484.661 1527.57 Q483.874 1529.47 481.767 1532.07 Q481.189 1532.74 478.087 1535.95 Q474.985 1539.15 469.337 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M931.882 1518.36 L920.077 1536.81 L931.882 1536.81 L931.882 1518.36 M930.656 1514.29 L936.535 1514.29 L936.535 1536.81 L941.466 1536.81 L941.466 1540.7 L936.535 1540.7 L936.535 1548.85 L931.882 1548.85 L931.882 1540.7 L916.281 1540.7 L916.281 1536.19 L930.656 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M1383.47 1529.7 Q1380.32 1529.7 1378.47 1531.86 Q1376.64 1534.01 1376.64 1537.76 Q1376.64 1541.49 1378.47 1543.66 Q1380.32 1545.82 1383.47 1545.82 Q1386.62 1545.82 1388.44 1543.66 Q1390.3 1541.49 1390.3 1537.76 Q1390.3 1534.01 1388.44 1531.86 Q1386.62 1529.7 1383.47 1529.7 M1392.75 1515.05 L1392.75 1519.31 Q1390.99 1518.48 1389.18 1518.04 Q1387.4 1517.6 1385.64 1517.6 Q1381.01 1517.6 1378.56 1520.72 Q1376.13 1523.85 1375.78 1530.17 Q1377.15 1528.15 1379.21 1527.09 Q1381.27 1526 1383.75 1526 Q1388.95 1526 1391.96 1529.17 Q1395 1532.32 1395 1537.76 Q1395 1543.08 1391.85 1546.3 Q1388.7 1549.52 1383.47 1549.52 Q1377.47 1549.52 1374.3 1544.94 Q1371.13 1540.33 1371.13 1531.6 Q1371.13 1523.41 1375.02 1518.55 Q1378.91 1513.66 1385.46 1513.66 Q1387.22 1513.66 1389 1514.01 Q1390.81 1514.36 1392.75 1515.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M1837.25 1532.44 Q1833.92 1532.44 1832 1534.22 Q1830.1 1536 1830.1 1539.13 Q1830.1 1542.25 1832 1544.03 Q1833.92 1545.82 1837.25 1545.82 Q1840.58 1545.82 1842.51 1544.03 Q1844.43 1542.23 1844.43 1539.13 Q1844.43 1536 1842.51 1534.22 Q1840.61 1532.44 1837.25 1532.44 M1832.58 1530.45 Q1829.57 1529.7 1827.88 1527.64 Q1826.21 1525.58 1826.21 1522.62 Q1826.21 1518.48 1829.15 1516.07 Q1832.11 1513.66 1837.25 1513.66 Q1842.41 1513.66 1845.35 1516.07 Q1848.29 1518.48 1848.29 1522.62 Q1848.29 1525.58 1846.6 1527.64 Q1844.94 1529.7 1841.95 1530.45 Q1845.33 1531.23 1847.2 1533.52 Q1849.1 1535.82 1849.1 1539.13 Q1849.1 1544.15 1846.02 1546.83 Q1842.97 1549.52 1837.25 1549.52 Q1831.53 1549.52 1828.46 1546.83 Q1825.4 1544.15 1825.4 1539.13 Q1825.4 1535.82 1827.3 1533.52 Q1829.2 1531.23 1832.58 1530.45 M1830.86 1523.06 Q1830.86 1525.75 1832.53 1527.25 Q1834.22 1528.76 1837.25 1528.76 Q1840.26 1528.76 1841.95 1527.25 Q1843.66 1525.75 1843.66 1523.06 Q1843.66 1520.38 1841.95 1518.87 Q1840.26 1517.37 1837.25 1517.37 Q1834.22 1517.37 1832.53 1518.87 Q1830.86 1520.38 1830.86 1523.06 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M2266.13 1544.91 L2273.77 1544.91 L2273.77 1518.55 L2265.46 1520.21 L2265.46 1515.95 L2273.72 1514.29 L2278.4 1514.29 L2278.4 1544.91 L2286.04 1544.91 L2286.04 1548.85 L2266.13 1548.85 L2266.13 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M2305.48 1517.37 Q2301.87 1517.37 2300.04 1520.93 Q2298.23 1524.47 2298.23 1531.6 Q2298.23 1538.71 2300.04 1542.27 Q2301.87 1545.82 2305.48 1545.82 Q2309.11 1545.82 2310.92 1542.27 Q2312.75 1538.71 2312.75 1531.6 Q2312.75 1524.47 2310.92 1520.93 Q2309.11 1517.37 2305.48 1517.37 M2305.48 1513.66 Q2311.29 1513.66 2314.35 1518.27 Q2317.42 1522.85 2317.42 1531.6 Q2317.42 1540.33 2314.35 1544.94 Q2311.29 1549.52 2305.48 1549.52 Q2299.67 1549.52 2296.59 1544.94 Q2293.54 1540.33 2293.54 1531.6 Q2293.54 1522.85 2296.59 1518.27 Q2299.67 1513.66 2305.48 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  186.274,1461.02 2352.76,1461.02 \n  \"/>\n<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  186.274,1215.96 2352.76,1215.96 \n  \"/>\n<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  186.274,970.886 2352.76,970.886 \n  \"/>\n<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  186.274,725.818 2352.76,725.818 \n  \"/>\n<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  186.274,480.749 2352.76,480.749 \n  \"/>\n<polyline clip-path=\"url(#clip632)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  186.274,235.68 2352.76,235.68 \n  \"/>\n<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  186.274,1486.45 186.274,47.2441 \n  \"/>\n<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  186.274,1461.02 205.172,1461.02 \n  \"/>\n<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  186.274,1215.96 205.172,1215.96 \n  \"/>\n<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  186.274,970.886 205.172,970.886 \n  \"/>\n<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  186.274,725.818 205.172,725.818 \n  \"/>\n<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  186.274,480.749 205.172,480.749 \n  \"/>\n<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  186.274,235.68 205.172,235.68 \n  \"/>\n<path clip-path=\"url(#clip630)\" d=\"M62.9365 1446.82 Q59.3254 1446.82 57.4967 1450.39 Q55.6912 1453.93 55.6912 1461.06 Q55.6912 1468.17 57.4967 1471.73 Q59.3254 1475.27 62.9365 1475.27 Q66.5707 1475.27 68.3763 1471.73 Q70.205 1468.17 70.205 1461.06 Q70.205 1453.93 68.3763 1450.39 Q66.5707 1446.82 62.9365 1446.82 M62.9365 1443.12 Q68.7467 1443.12 71.8022 1447.73 Q74.8809 1452.31 74.8809 1461.06 Q74.8809 1469.79 71.8022 1474.39 Q68.7467 1478.98 62.9365 1478.98 Q57.1264 1478.98 54.0477 1474.39 Q50.9921 1469.79 50.9921 1461.06 Q50.9921 1452.31 54.0477 1447.73 Q57.1264 1443.12 62.9365 1443.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M83.0984 1472.42 L87.9827 1472.42 L87.9827 1478.3 L83.0984 1478.3 L83.0984 1472.42 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M108.168 1446.82 Q104.557 1446.82 102.728 1450.39 Q100.922 1453.93 100.922 1461.06 Q100.922 1468.17 102.728 1471.73 Q104.557 1475.27 108.168 1475.27 Q111.802 1475.27 113.608 1471.73 Q115.436 1468.17 115.436 1461.06 Q115.436 1453.93 113.608 1450.39 Q111.802 1446.82 108.168 1446.82 M108.168 1443.12 Q113.978 1443.12 117.033 1447.73 Q120.112 1452.31 120.112 1461.06 Q120.112 1469.79 117.033 1474.39 Q113.978 1478.98 108.168 1478.98 Q102.358 1478.98 99.2789 1474.39 Q96.2234 1469.79 96.2234 1461.06 Q96.2234 1452.31 99.2789 1447.73 Q102.358 1443.12 108.168 1443.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M138.33 1446.82 Q134.719 1446.82 132.89 1450.39 Q131.084 1453.93 131.084 1461.06 Q131.084 1468.17 132.89 1471.73 Q134.719 1475.27 138.33 1475.27 Q141.964 1475.27 143.769 1471.73 Q145.598 1468.17 145.598 1461.06 Q145.598 1453.93 143.769 1450.39 Q141.964 1446.82 138.33 1446.82 M138.33 1443.12 Q144.14 1443.12 147.195 1447.73 Q150.274 1452.31 150.274 1461.06 Q150.274 1469.79 147.195 1474.39 Q144.14 1478.98 138.33 1478.98 Q132.519 1478.98 129.441 1474.39 Q126.385 1469.79 126.385 1461.06 Q126.385 1452.31 129.441 1447.73 Q132.519 1443.12 138.33 1443.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M63.9319 1201.75 Q60.3208 1201.75 58.4921 1205.32 Q56.6865 1208.86 56.6865 1215.99 Q56.6865 1223.1 58.4921 1226.66 Q60.3208 1230.2 63.9319 1230.2 Q67.5661 1230.2 69.3717 1226.66 Q71.2004 1223.1 71.2004 1215.99 Q71.2004 1208.86 69.3717 1205.32 Q67.5661 1201.75 63.9319 1201.75 M63.9319 1198.05 Q69.742 1198.05 72.7976 1202.66 Q75.8763 1207.24 75.8763 1215.99 Q75.8763 1224.72 72.7976 1229.32 Q69.742 1233.91 63.9319 1233.91 Q58.1217 1233.91 55.043 1229.32 Q51.9875 1224.72 51.9875 1215.99 Q51.9875 1207.24 55.043 1202.66 Q58.1217 1198.05 63.9319 1198.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M84.0938 1227.36 L88.978 1227.36 L88.978 1233.24 L84.0938 1233.24 L84.0938 1227.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M109.163 1201.75 Q105.552 1201.75 103.723 1205.32 Q101.918 1208.86 101.918 1215.99 Q101.918 1223.1 103.723 1226.66 Q105.552 1230.2 109.163 1230.2 Q112.797 1230.2 114.603 1226.66 Q116.432 1223.1 116.432 1215.99 Q116.432 1208.86 114.603 1205.32 Q112.797 1201.75 109.163 1201.75 M109.163 1198.05 Q114.973 1198.05 118.029 1202.66 Q121.107 1207.24 121.107 1215.99 Q121.107 1224.72 118.029 1229.32 Q114.973 1233.91 109.163 1233.91 Q103.353 1233.91 100.274 1229.32 Q97.2187 1224.72 97.2187 1215.99 Q97.2187 1207.24 100.274 1202.66 Q103.353 1198.05 109.163 1198.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M129.371 1198.68 L147.728 1198.68 L147.728 1202.61 L133.654 1202.61 L133.654 1211.08 Q134.672 1210.74 135.691 1210.57 Q136.709 1210.39 137.728 1210.39 Q143.515 1210.39 146.894 1213.56 Q150.274 1216.73 150.274 1222.15 Q150.274 1227.73 146.802 1230.83 Q143.33 1233.91 137.01 1233.91 Q134.834 1233.91 132.566 1233.54 Q130.32 1233.17 127.913 1232.42 L127.913 1227.73 Q129.996 1228.86 132.219 1229.42 Q134.441 1229.97 136.918 1229.97 Q140.922 1229.97 143.26 1227.86 Q145.598 1225.76 145.598 1222.15 Q145.598 1218.54 143.26 1216.43 Q140.922 1214.32 136.918 1214.32 Q135.043 1214.32 133.168 1214.74 Q131.316 1215.16 129.371 1216.04 L129.371 1198.68 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M62.9365 956.685 Q59.3254 956.685 57.4967 960.25 Q55.6912 963.791 55.6912 970.921 Q55.6912 978.028 57.4967 981.592 Q59.3254 985.134 62.9365 985.134 Q66.5707 985.134 68.3763 981.592 Q70.205 978.028 70.205 970.921 Q70.205 963.791 68.3763 960.25 Q66.5707 956.685 62.9365 956.685 M62.9365 952.981 Q68.7467 952.981 71.8022 957.588 Q74.8809 962.171 74.8809 970.921 Q74.8809 979.648 71.8022 984.254 Q68.7467 988.838 62.9365 988.838 Q57.1264 988.838 54.0477 984.254 Q50.9921 979.648 50.9921 970.921 Q50.9921 962.171 54.0477 957.588 Q57.1264 952.981 62.9365 952.981 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M83.0984 982.287 L87.9827 982.287 L87.9827 988.166 L83.0984 988.166 L83.0984 982.287 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M98.978 984.231 L106.617 984.231 L106.617 957.866 L98.3067 959.532 L98.3067 955.273 L106.571 953.606 L111.246 953.606 L111.246 984.231 L118.885 984.231 L118.885 988.166 L98.978 988.166 L98.978 984.231 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M138.33 956.685 Q134.719 956.685 132.89 960.25 Q131.084 963.791 131.084 970.921 Q131.084 978.028 132.89 981.592 Q134.719 985.134 138.33 985.134 Q141.964 985.134 143.769 981.592 Q145.598 978.028 145.598 970.921 Q145.598 963.791 143.769 960.25 Q141.964 956.685 138.33 956.685 M138.33 952.981 Q144.14 952.981 147.195 957.588 Q150.274 962.171 150.274 970.921 Q150.274 979.648 147.195 984.254 Q144.14 988.838 138.33 988.838 Q132.519 988.838 129.441 984.254 Q126.385 979.648 126.385 970.921 Q126.385 962.171 129.441 957.588 Q132.519 952.981 138.33 952.981 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M63.9319 711.616 Q60.3208 711.616 58.4921 715.181 Q56.6865 718.723 56.6865 725.852 Q56.6865 732.959 58.4921 736.523 Q60.3208 740.065 63.9319 740.065 Q67.5661 740.065 69.3717 736.523 Q71.2004 732.959 71.2004 725.852 Q71.2004 718.723 69.3717 715.181 Q67.5661 711.616 63.9319 711.616 M63.9319 707.913 Q69.742 707.913 72.7976 712.519 Q75.8763 717.102 75.8763 725.852 Q75.8763 734.579 72.7976 739.186 Q69.742 743.769 63.9319 743.769 Q58.1217 743.769 55.043 739.186 Q51.9875 734.579 51.9875 725.852 Q51.9875 717.102 55.043 712.519 Q58.1217 707.913 63.9319 707.913 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M84.0938 737.218 L88.978 737.218 L88.978 743.098 L84.0938 743.098 L84.0938 737.218 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M99.9733 739.162 L107.612 739.162 L107.612 712.797 L99.3021 714.463 L99.3021 710.204 L107.566 708.538 L112.242 708.538 L112.242 739.162 L119.881 739.162 L119.881 743.098 L99.9733 743.098 L99.9733 739.162 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M129.371 708.538 L147.728 708.538 L147.728 712.473 L133.654 712.473 L133.654 720.945 Q134.672 720.598 135.691 720.436 Q136.709 720.25 137.728 720.25 Q143.515 720.25 146.894 723.422 Q150.274 726.593 150.274 732.01 Q150.274 737.588 146.802 740.69 Q143.33 743.769 137.01 743.769 Q134.834 743.769 132.566 743.398 Q130.32 743.028 127.913 742.287 L127.913 737.588 Q129.996 738.723 132.219 739.278 Q134.441 739.834 136.918 739.834 Q140.922 739.834 143.26 737.727 Q145.598 735.621 145.598 732.01 Q145.598 728.399 143.26 726.292 Q140.922 724.186 136.918 724.186 Q135.043 724.186 133.168 724.602 Q131.316 725.019 129.371 725.899 L129.371 708.538 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M62.9365 466.547 Q59.3254 466.547 57.4967 470.112 Q55.6912 473.654 55.6912 480.783 Q55.6912 487.89 57.4967 491.455 Q59.3254 494.996 62.9365 494.996 Q66.5707 494.996 68.3763 491.455 Q70.205 487.89 70.205 480.783 Q70.205 473.654 68.3763 470.112 Q66.5707 466.547 62.9365 466.547 M62.9365 462.844 Q68.7467 462.844 71.8022 467.45 Q74.8809 472.034 74.8809 480.783 Q74.8809 489.51 71.8022 494.117 Q68.7467 498.7 62.9365 498.7 Q57.1264 498.7 54.0477 494.117 Q50.9921 489.51 50.9921 480.783 Q50.9921 472.034 54.0477 467.45 Q57.1264 462.844 62.9365 462.844 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M83.0984 492.149 L87.9827 492.149 L87.9827 498.029 L83.0984 498.029 L83.0984 492.149 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M102.196 494.094 L118.515 494.094 L118.515 498.029 L96.5706 498.029 L96.5706 494.094 Q99.2326 491.339 103.816 486.709 Q108.422 482.057 109.603 480.714 Q111.848 478.191 112.728 476.455 Q113.631 474.696 113.631 473.006 Q113.631 470.251 111.686 468.515 Q109.765 466.779 106.663 466.779 Q104.464 466.779 102.01 467.543 Q99.5798 468.307 96.8021 469.858 L96.8021 465.135 Q99.6261 464.001 102.08 463.422 Q104.534 462.844 106.571 462.844 Q111.941 462.844 115.135 465.529 Q118.33 468.214 118.33 472.705 Q118.33 474.834 117.52 476.756 Q116.733 478.654 114.626 481.246 Q114.047 481.918 110.946 485.135 Q107.844 488.33 102.196 494.094 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M138.33 466.547 Q134.719 466.547 132.89 470.112 Q131.084 473.654 131.084 480.783 Q131.084 487.89 132.89 491.455 Q134.719 494.996 138.33 494.996 Q141.964 494.996 143.769 491.455 Q145.598 487.89 145.598 480.783 Q145.598 473.654 143.769 470.112 Q141.964 466.547 138.33 466.547 M138.33 462.844 Q144.14 462.844 147.195 467.45 Q150.274 472.034 150.274 480.783 Q150.274 489.51 147.195 494.117 Q144.14 498.7 138.33 498.7 Q132.519 498.7 129.441 494.117 Q126.385 489.51 126.385 480.783 Q126.385 472.034 129.441 467.45 Q132.519 462.844 138.33 462.844 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M63.9319 221.479 Q60.3208 221.479 58.4921 225.043 Q56.6865 228.585 56.6865 235.715 Q56.6865 242.821 58.4921 246.386 Q60.3208 249.928 63.9319 249.928 Q67.5661 249.928 69.3717 246.386 Q71.2004 242.821 71.2004 235.715 Q71.2004 228.585 69.3717 225.043 Q67.5661 221.479 63.9319 221.479 M63.9319 217.775 Q69.742 217.775 72.7976 222.381 Q75.8763 226.965 75.8763 235.715 Q75.8763 244.441 72.7976 249.048 Q69.742 253.631 63.9319 253.631 Q58.1217 253.631 55.043 249.048 Q51.9875 244.441 51.9875 235.715 Q51.9875 226.965 55.043 222.381 Q58.1217 217.775 63.9319 217.775 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M84.0938 247.08 L88.978 247.08 L88.978 252.96 L84.0938 252.96 L84.0938 247.08 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M103.191 249.025 L119.51 249.025 L119.51 252.96 L97.566 252.96 L97.566 249.025 Q100.228 246.27 104.811 241.641 Q109.418 236.988 110.598 235.645 Q112.844 233.122 113.723 231.386 Q114.626 229.627 114.626 227.937 Q114.626 225.182 112.682 223.446 Q110.76 221.71 107.658 221.71 Q105.459 221.71 103.006 222.474 Q100.575 223.238 97.7974 224.789 L97.7974 220.067 Q100.621 218.932 103.075 218.354 Q105.529 217.775 107.566 217.775 Q112.936 217.775 116.131 220.46 Q119.325 223.145 119.325 227.636 Q119.325 229.766 118.515 231.687 Q117.728 233.585 115.621 236.178 Q115.043 236.849 111.941 240.066 Q108.839 243.261 103.191 249.025 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M129.371 218.4 L147.728 218.4 L147.728 222.335 L133.654 222.335 L133.654 230.807 Q134.672 230.46 135.691 230.298 Q136.709 230.113 137.728 230.113 Q143.515 230.113 146.894 233.284 Q150.274 236.455 150.274 241.872 Q150.274 247.451 146.802 250.553 Q143.33 253.631 137.01 253.631 Q134.834 253.631 132.566 253.261 Q130.32 252.89 127.913 252.15 L127.913 247.451 Q129.996 248.585 132.219 249.141 Q134.441 249.696 136.918 249.696 Q140.922 249.696 143.26 247.59 Q145.598 245.483 145.598 241.872 Q145.598 238.261 143.26 236.154 Q140.922 234.048 136.918 234.048 Q135.043 234.048 133.168 234.465 Q131.316 234.881 129.371 235.761 L129.371 218.4 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip632)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  247.59,87.9763 474.684,1031.66 701.779,1364.59 928.873,1445.72 \n  \"/>\n<path clip-path=\"url(#clip630)\" d=\"\nM1987.39 198.898 L2280.54 198.898 L2280.54 95.2176 L1987.39 95.2176  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<polyline clip-path=\"url(#clip630)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1987.39,198.898 2280.54,198.898 2280.54,95.2176 1987.39,95.2176 1987.39,198.898 \n  \"/>\n<polyline clip-path=\"url(#clip630)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  2011.46,147.058 2155.89,147.058 \n  \"/>\n<path clip-path=\"url(#clip630)\" d=\"M2193.81 166.745 Q2192 171.375 2190.29 172.787 Q2188.58 174.199 2185.71 174.199 L2182.3 174.199 L2182.3 170.634 L2184.8 170.634 Q2186.56 170.634 2187.53 169.8 Q2188.51 168.967 2189.69 165.865 L2190.45 163.921 L2179.97 138.412 L2184.48 138.412 L2192.58 158.689 L2200.68 138.412 L2205.2 138.412 L2193.81 166.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip630)\" d=\"M2212.49 160.402 L2220.13 160.402 L2220.13 134.037 L2211.82 135.703 L2211.82 131.444 L2220.08 129.778 L2224.76 129.778 L2224.76 160.402 L2232.4 160.402 L2232.4 164.338 L2212.49 164.338 L2212.49 160.402 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show Plots.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(net,test[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Accuracy: 23.333333333333332%\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(net,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
