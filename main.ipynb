{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temat 1. Własna sieć neuronowa\n",
    "Celem projektu jest samodzielne zaimplementowanie prostej sieci neuronowej i przetestowanie jej na wybranym przez siebie przykładzie.\n",
    "\n",
    "Podstawowym założeniem projektu jest własnoręczne zaimplementowanie automatycznego różniczkowania w celu wyznaczania pochodnych warstw potrzebnych do wstecznej   propagacji błędów. Dopuszczalne jest wykorzystanie różniczkowanie w przód (ang. Forward Accumulation), różniczkowanie w tył (ang. Reverse Accumulation) oraz różniczkowanie oparte o generację kodu (ang. source-to-source differentiation).\n",
    "\n",
    "Do implementacji optymalizatorów dokonujących właściwego uczenia sieci można wykorzystać kod zamieszczony w książce \"Algorithms for Optimization\" [1].\n",
    "\n",
    "klasyfikacja cyfr (Digits MNIST dataset)  \n",
    "Bibliografia:  \n",
    "[1] Mykel J. Kochenderfer, Tim A. Wheeler, 2019, Algorithms for Optimization, MIT Press.  \n",
    "[2] Martin T. Hagan et. al, Neural Network Design, pp. 915-918, url: https://hagan.okstate.edu/NNDesign.pdf  \n",
    "[3] 3blue1brown: czym są sieci neuronowe? https://www.youtube.com/watch?v=aircAruvnKk  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `e:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"./project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Manifest.toml`"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Manifest.toml`"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Manifest.toml`"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Manifest.toml`"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `E:\\Documents\\1. Studia\\MAGISTERSKIE\\Algorytmy w inż danych\\Custom-Julia-NN\\project\\Manifest.toml`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Pkg.add(\"MLDatasets\")\n",
    "Pkg.add(\"IJulia\")\n",
    "Pkg.add(\"StableRNGs\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"PyPlot\")\n",
    "ENV[\"PYTHON\"]=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape: (28, 28, 1, 60000)\n",
      "Test X shape: (28, 28, 1, 10000)\n",
      "Train Y shape: (10, 60000)\n",
      "Test Y shape: (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "using MLDatasets\n",
    "using StableRNGs\n",
    "train_x, train_y = MNIST.traindata(Float32);\n",
    "test_x, test_y = MNIST.testdata(Float32);\n",
    "Y_labels = [0,1,2,3,4,5,6,7,8,9]\n",
    "train_size = size(train_x)\n",
    "test_size = size(test_x)\n",
    "train_x = reshape(train_x, (train_size[1],train_size[2],1,train_size[3]))\n",
    "test_x = reshape(test_x, (test_size[1],test_size[2],1,test_size[3]))\n",
    "println(\"Train X shape: \",size(train_x));\n",
    "println(\"Test X shape: \",size((test_x)));\n",
    "test_test_y = test_y\n",
    "test_y= Y_labels  .== permutedims(test_y)\n",
    "train_y= Y_labels .== permutedims(train_y)\n",
    "println(\"Train Y shape: \",size(train_y));\n",
    "println(\"Test Y shape: \",size((test_y)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Automatic differentation- foward accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dual number\n",
    "struct Dual{T <:Number} <:Number\n",
    "     v::T\n",
    "    dv::T\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overloading functions and operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Base: +, -, *, /\n",
    "-(x::Dual)          = Dual(-x.v,       -x.dv)\n",
    "+(x::Dual, y::Dual) = Dual( x.v + y.v,  x.dv + y.dv)\n",
    "-(x::Dual, y::Dual) = Dual( x.v - y.v,  x.dv - y.dv)\n",
    "*(x::Dual, y::Dual) = Dual( x.v * y.v,  x.dv * y.v + x.v * y.dv)\n",
    "/(x::Dual, y::Dual) = Dual( x.v / y.v, (x.dv * y.v - x.v * y.dv)/y.v^2)\n",
    "\n",
    "import Base: abs, sin, cos, tan, exp, sqrt, isless\n",
    "abs(x::Dual)  = Dual(abs(x.v),sign(x.v)*x.dv)\n",
    "sin(x::Dual)  = Dual(sin(x.v), cos(x.v)*x.dv)\n",
    "cos(x::Dual)  = Dual(cos(x.v),-sin(x.v)*x.dv)\n",
    "tan(x::Dual)  = Dual(tan(x.v), one(x.v)*x.dv + tan(x.v)^2*x.dv)\n",
    "exp(x::Dual)  = Dual(exp(x.v), exp(x.v)*x.dv)\n",
    "sqrt(x::Dual) = Dual(sqrt(x.v),.5/sqrt(x.v) * x.dv)\n",
    "isless(x::Dual, y::Dual) = x.v < y.v;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dual{Float64}[Dual(1, 2), Dual(3, 0)] = Dual{Float64}[(1.0) + [2.0ϵ], (3.0) + [0.0ϵ]]\n",
      "Dual{Float64}[1, 2, 3] = Dual{Float64}[(1.0) + [0.0ϵ], (2.0) + [0.0ϵ], (3.0) + [0.0ϵ]]\n",
      "Dual(1, 2) * 3 = (3) + [6ϵ]\n"
     ]
    }
   ],
   "source": [
    "import Base: convert, promote_rule\n",
    "\n",
    "convert(::Type{Dual{T}}, x::Dual) where T = Dual(convert(T, x.v), convert(T, x.dv))\n",
    "@show Dual{Float64}[Dual(1,2), Dual(3,0)];\n",
    "convert(::Type{Dual{T}}, x::Number) where T = Dual(convert(T, x), zero(T))\n",
    "@show Dual{Float64}[1, 2, 3];\n",
    "promote_rule(::Type{Dual{T}}, ::Type{R}) where {T,R} = Dual{promote_type(T,R)}\n",
    "@show Dual(1,2) * 3;\n",
    "\n",
    "import Base: show\n",
    "show(io::IO, x::Dual) = print(io, \"(\", x.v, \") + [\", x.dv, \"ϵ]\");\n",
    "value(x::Dual) = x.v;\n",
    "partials(x::Dual) = x.dv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "derivative (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D = derivative(f, x) = partials(f(Dual(x, one(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jacobian (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "J = function jacobian(f, args::Vector{T}) where {T <:Number}\n",
    "    jacobian_columns = Matrix{T}[]\n",
    "    \n",
    "    for i=1:length(args)\n",
    "        x = Dual{T}[]\n",
    "        for j=1:length(args)\n",
    "            seed = (i == j)\n",
    "            push!(x, seed ?\n",
    "                Dual(args[j], one(args[j])) :\n",
    "                Dual(args[j],zero(args[j])) )\n",
    "        end\n",
    "        column = partials.([f(x)...])\n",
    "        push!(jacobian_columns, column[:,:])\n",
    "    end\n",
    "    hcat(jacobian_columns...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hessian (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "H = function hessian(f, args::Vector)\n",
    "    ∇f(x::Vector) = J(f, x)\n",
    "    J(∇f, args)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LinearAlgebra: diagm\n",
    "diagonal(m) = diagm(0 => vec(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tanh (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "softmax(x)  =  exp.(x) ./ sum(exp.(x));\n",
    "dsoftmax(x) = (softmax(x) |> diagonal) .- softmax(x) * (softmax(x) |> transpose);\n",
    "\n",
    "ReLU(x) = max(zero(x), x)\n",
    "σ(x) = one(x) / (one(x) + exp(-x))\n",
    "tanh(x) = 2.0 / (one(x) + exp(-2.0x)) - one(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "binary_cross_entropy (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_squared_loss(y::Vector, ŷ::Vector) = sum(0.5(y - ŷ).^2)\n",
    "binary_cross_entropy(y::Vector, ŷ::Vector) = let \n",
    "    epsilon = eps(1.0)\n",
    "    ## Avoding 0 , 1 in log argument\n",
    "    ŷ = [max(i, epsilon) for i in ŷ]\n",
    "    ŷ = [min(i, 1-epsilon) for i in ŷ]\n",
    "    return -sum(y .* log.(ŷ) + (1 .- y) .* log.(1 .- ŷ)) / length(y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_cross_entropy([1, 1, 0.01], [1, 1, 0]) = 0.1201455112970574\n",
      "mean_squared_loss([1, 1, 1], [0, 0, 0]) = 1.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@show binary_cross_entropy([1,1,0.01],[1,1,0])\n",
    "@show mean_squared_loss([1,1,1],[0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fullyconnected (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fullyconnected(w::Vector, n::Number, m::Number, v::Vector, activation::Function) = activation.(reshape(w, n, m) * v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7820978145137796"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Wh  = randn(10,2)\n",
    "Wo  = randn(1,10)\n",
    "dWh = similar(Wh)\n",
    "dWo = similar(Wo)\n",
    "x = [1.98;4.434]\n",
    "y = [0.064]\n",
    "E = Float64[]\n",
    "\n",
    "function net(x, wh, wo, y)\n",
    "    x̂ = fullyconnected(wh, 10, 2, x, σ)\n",
    "    ŷ = fullyconnected(wo, 1, 10, x̂, u->u)\n",
    "    E = mean_squared_loss(y, ŷ)\n",
    "end\n",
    "Ei = net(x, Wh[:], Wo[:], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnet_Wh(x, wh, wo, y) = J(w -> net(x, w, wo, y), wh);\n",
    "dWh[:] = dnet_Wh(x, Wh[:], Wo[:], y);\n",
    "\n",
    "dnet_Wo(x, wh, wo, y) = J(w -> net(x, wh, w, y), wo);\n",
    "dWo[:] = dnet_Wo(x, Wh[:], Wo[:], y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
